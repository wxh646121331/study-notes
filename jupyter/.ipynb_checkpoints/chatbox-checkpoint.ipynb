{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46177609-f81a-46f4-84f8-703438e16fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wuxinhong/jupyter\n",
      "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\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://ee4c2928cac6f03ee7.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/gradio/routes.py\", line 422, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1323, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1051, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/var/folders/d3/d_brn0w57xd79jhb2vwb9mg40000gn/T/ipykernel_52125/1039341781.py\", line 29, in chatbot\n",
      "    response = index.query(input_text, response_mode=\"compact\")\n",
      "AttributeError: 'GPTVectorStoreIndex' object has no attribute 'query'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/gradio/routes.py\", line 422, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1323, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1051, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/var/folders/d3/d_brn0w57xd79jhb2vwb9mg40000gn/T/ipykernel_52125/1039341781.py\", line 29, in chatbot\n",
      "    response = index.query(input_text, response_mode=\"compact\")\n",
      "AttributeError: 'GPTVectorStoreIndex' object has no attribute 'query'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gradio as gr\n",
    "from llama_index import SimpleDirectoryReader, LangchainEmbedding, GPTListIndex,GPTVectorStoreIndex, PromptHelper, LLMPredictor, ServiceContext\n",
    "# import openai\n",
    "from langchain import OpenAI\n",
    "os.chdir(r'/Users/wuxinhong/jupyter')\n",
    "print(os.getcwd())\n",
    "openai_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "print(openai_key)\n",
    "\n",
    "def construct_index(directory_path):\n",
    "    max_input_size = 4096\n",
    "    num_outputs = 2000\n",
    "    max_chunk_overlap = 20\n",
    "    chunk_size_limit = 600\n",
    "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
    "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.7, model_name=\"gpt-3.5-turbo\", max_tokens=num_outputs))\n",
    "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
    "    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
    "    index = GPTVectorStoreIndex.from_documents(documents,service_context=service_context)\n",
    "    # index.save_to_disk('index.json')\n",
    "    index.storage_context.persist()\n",
    "    return index\n",
    "\n",
    "def chatbot(input_text):\n",
    "    documents = SimpleDirectoryReader('storage').load_data()\n",
    "    index = GPTVectorStoreIndex.from_documents(documents)\n",
    "    query_engine = index.as_query_engine()\n",
    "    response = query_engine.query(input_text)\n",
    "    # response = index.query(input_text, response_mode=\"compact\")\n",
    "    return response.response\n",
    "\n",
    "iface = gr.Interface(fn=chatbot,\n",
    "                     inputs=gr.inputs.Textbox(lines=7, label=\"输入您的文本\"),\n",
    "                     outputs=\"text\",\n",
    "                     title=\"AI 知识库聊天机器人\")\n",
    "\n",
    "index = construct_index(\"docs\")\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb19c886-4af5-4be2-a537-319dcd5ec4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wuxinhong/jupyter\n",
      "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\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/gradio/inputs.py:30: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/gradio/inputs.py:30: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://567e1e2e8221023b49.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://567e1e2e8221023b49.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/urllib3/connection.py\", line 174, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/urllib3/util/connection.py\", line 95, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 386, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 1042, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/urllib3/connection.py\", line 363, in connect\n",
      "    self.sock = conn = self._new_conn()\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/urllib3/connection.py\", line 186, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7fd8447ba9b0>: Failed to establish a new connection: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/requests/adapters.py\", line 489, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 815, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 815, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/urllib3/util/retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/embeddings (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fd8447ba9b0>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/openai/api_requestor.py\", line 520, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/requests/sessions.py\", line 587, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/requests/sessions.py\", line 701, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/requests/adapters.py\", line 565, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/embeddings (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fd8447ba9b0>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/tenacity/__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/llama_index/embeddings/openai.py\", line 150, in get_embeddings\n",
      "    data = openai.Embedding.create(input=list_of_text, model=engine, **kwargs).data\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/openai/api_resources/embedding.py\", line 33, in create\n",
      "    response = super().create(*args, **kwargs)\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/openai/api_requestor.py\", line 220, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/openai/api_requestor.py\", line 533, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/embeddings (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fd8447ba9b0>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/gradio/routes.py\", line 422, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1323, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1051, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/var/folders/d3/d_brn0w57xd79jhb2vwb9mg40000gn/T/ipykernel_52299/1425024881.py\", line 15, in chatbot\n",
      "    index = GPTVectorStoreIndex.from_documents(documents)\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/llama_index/indices/base.py\", line 93, in from_documents\n",
      "    return cls(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py\", line 44, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/llama_index/indices/base.py\", line 65, in __init__\n",
      "    index_struct = self.build_index_from_nodes(nodes)\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/llama_index/token_counter/token_counter.py\", line 78, in wrapped_llm_predict\n",
      "    f_return_val = f(_self, *args, **kwargs)\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py\", line 201, in build_index_from_nodes\n",
      "    return self._build_index_from_nodes(nodes)\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py\", line 190, in _build_index_from_nodes\n",
      "    self._add_nodes_to_index(index_struct, nodes)\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py\", line 166, in _add_nodes_to_index\n",
      "    embedding_results = self._get_node_embedding_results(nodes)\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py\", line 85, in _get_node_embedding_results\n",
      "    ) = self._service_context.embed_model.get_queued_text_embeddings()\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/llama_index/embeddings/base.py\", line 167, in get_queued_text_embeddings\n",
      "    embeddings = self._get_text_embeddings(cur_batch_texts)\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/llama_index/embeddings/openai.py\", line 267, in _get_text_embeddings\n",
      "    return get_embeddings(\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/tenacity/__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/tenacity/__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"/Users/wuxinhong/miniconda3/lib/python3.10/site-packages/tenacity/__init__.py\", line 326, in iter\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x7fd85443b880 state=finished raised APIConnectionError>]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gradio as gr\n",
    "from llama_index import SimpleDirectoryReader, LangchainEmbedding, GPTListIndex,GPTVectorStoreIndex, PromptHelper, LLMPredictor, ServiceContext\n",
    "# import openai\n",
    "from langchain import OpenAI\n",
    "os.chdir(r'/Users/wuxinhong/jupyter')\n",
    "print(os.getcwd())\n",
    "openai_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "print(openai_key)\n",
    "\n",
    "def chatbot(input_text):\n",
    "    # index = GPTVectorStoreIndex.load_from_disk('index.json')\n",
    "    documents = SimpleDirectoryReader('storage').load_data()\n",
    "    index = GPTVectorStoreIndex.from_documents(documents)\n",
    "    query_engine = index.as_query_engine()\n",
    "    response = query_engine.query(input_text)\n",
    "    # response = index.query(input_text, response_mode=\"compact\")\n",
    "    return response.response\n",
    "\n",
    "iface = gr.Interface(fn=chatbot,\n",
    "                     inputs=gr.inputs.Textbox(lines=7, label=\"输入您的文本\"),\n",
    "                     outputs=\"text\",\n",
    "                     title=\"AI 知识库聊天机器人\")\n",
    "\n",
    "# index = construct_index(\"docs\")\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082e7e3-15b7-4783-b79a-73aaa14e369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 加载 documents\n",
    "# documents = SimpleDirectoryReader('./storage').load_data()\n",
    "# index = GPTVectorStoreIndex.from_documents(documents)\n",
    "# index.storage_context.persist('index_mr_fujino')\n",
    "\n",
    "# 从磁盘重新加载：\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "os.chdir(r'/Users/wuxinhong/jupyter')\n",
    "print(os.getcwd())\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "# load index\n",
    "index = load_index_from_storage(storage_context)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"《江畔独步寻花》的作者是谁？\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
